{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*-coding:utf-8 -*-\n",
    "# File    :   barcode_plot.py\n",
    "# Time    :   22.06.2022\n",
    "# Author  :   Daniel Weston\n",
    "# Contact :   dtw545@bham.ac.uk\n",
    "\n",
    "# imports and hard coding of locations\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.interpolate as interp\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "\n",
    "folders = [\"c-glutamicum\", \"m-bovis\", \"r-erythropolis\"]\n",
    "data_dir = \"split-data\"\n",
    "plot_dir = \"figs\"\n",
    "\n",
    "# https://m-clark.github.io/data-processing-and-visualization/thinking_vis.html\n",
    "colour = px.colors.sequential.Plasma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get proper dpi\n",
    "def dpi_scaler(fig: go.Figure, dpi: int = 600) -> float:\n",
    "    \"\"\"\n",
    "    Set scale parameter when saving plotly figures to target dpi. Assumes that the border on A4 paper is 20mm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig : go.Figure\n",
    "        Figure to save.\n",
    "    dpi : int, optional\n",
    "        Target dpi.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Scale factor for figure to achieve target dpi.\n",
    "    \"\"\"\n",
    "    width = fig.layout.width if fig.layout.width is not None else 700\n",
    "    scale = (170 / 25.4) / (width / dpi)\n",
    "    return scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "sample = []\n",
    "repeat = []\n",
    "bacteria = []\n",
    "wavenumber = []\n",
    "intensity = []\n",
    "length = []\n",
    "for folder in (pbar := tqdm(folders)):\n",
    "    pbar.set_description(f\"Reading {folder}...\")\n",
    "    files = Path(data_dir, folder).glob(\"*.txt\")\n",
    "    for file in (pbar2 := tqdm(files, leave=False)):\n",
    "        pbar2.set_description(f\"Reading {file}\")\n",
    "        _, sample_number, repeat_number = file.stem.split(\"_\")\n",
    "        # cast these numbers to int\n",
    "        sample_number = int(sample_number.split(\"-\")[0])\n",
    "        repeat_number = int(repeat_number)\n",
    "        data = np.loadtxt(file)\n",
    "        wavenumber.append(list(data[:, 0]))\n",
    "        intensity.append(data[:, 1])\n",
    "        sample.append(sample_number)\n",
    "        repeat.append(repeat_number)\n",
    "        bacteria.append(file.parts[1])\n",
    "        length.append(data.shape[0])\n",
    "\n",
    "labels = pd.MultiIndex.from_arrays(\n",
    "    [bacteria, sample, repeat], names=[\"bacteria\", \"sample\", \"repeat\"]\n",
    ")\n",
    "df = pd.DataFrame(intensity, index=labels)\n",
    "# prune columns with NaN in, inplace for speed and memory reasons\n",
    "df.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep copy the dataframe to scale\n",
    "scaled_df = df.copy(deep=True)\n",
    "scaler = StandardScaler()\n",
    "scaled_df = pd.DataFrame(\n",
    "    scaler.fit_transform(scaled_df), columns=scaled_df.columns, index=labels\n",
    ")\n",
    "scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA for optimal component selection\n",
    "target_var = 0.999\n",
    "# use everything together\n",
    "pca_all = PCA(n_components=target_var)\n",
    "X_all = pca_all.fit(scaled_df)\n",
    "explained_variance_all = X_all.explained_variance_\n",
    "npts = explained_variance_all.shape[0]\n",
    "# use each repeat separately\n",
    "pca_repeats = [PCA(n_components=target_var) for i in range(3)]\n",
    "X_repeat = [\n",
    "    pca.fit(scaled_df.xs(i + 1, level=\"repeat\")) for i, pca in enumerate(pca_repeats)\n",
    "]\n",
    "explained_variance_repeats = [X.explained_variance_ for X in X_repeat]\n",
    "for var in explained_variance_repeats:\n",
    "    if (new_len := var.shape[0]) > npts:\n",
    "        npts = new_len\n",
    "# average the repeats and see what happens\n",
    "avg_df = scaled_df.groupby([\"bacteria\", \"sample\"]).mean()\n",
    "pca_avg = PCA(n_components=target_var)\n",
    "X_avg = pca_avg.fit(avg_df)\n",
    "explained_variance_avg = X_avg.explained_variance_\n",
    "npts = new_len if (new_len := explained_variance_avg.shape[0]) > npts else npts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "scree_plot = go.Figure()\n",
    "all_trace = go.Scatter(\n",
    "    y=explained_variance_all, name=\"all values\", mode=\"lines + markers\"\n",
    ")\n",
    "repeat_traces = [\n",
    "    go.Scatter(y=var, name=f\"repeat {i} values\", mode=\"lines + markers\")\n",
    "    for i, var in enumerate(explained_variance_repeats)\n",
    "]\n",
    "averaged_trace = go.Scatter(\n",
    "    y=explained_variance_avg, name=\"averaged values\", mode=\"lines + markers\"\n",
    ")\n",
    "decision_line = go.Scatter(\n",
    "    y=[1] * npts, mode=\"lines\", line=dict(dash=\"dash\", color=\"red\"), showlegend=False\n",
    ")\n",
    "scree_plot.add_traces([all_trace, *repeat_traces, averaged_trace, decision_line])\n",
    "scree_plot.update_xaxes(title=dict(text=\"Component\"))\n",
    "scree_plot.update_yaxes(title=dict(text=\"Eigenvalue\"))\n",
    "# scree_plot.update_layout(height = 1000)\n",
    "scree_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variance ratio plot\n",
    "ratio_plot = go.Figure()\n",
    "all_trace = go.Scatter(\n",
    "    y=100 * np.cumsum(explained_variance_all) / np.sum(explained_variance_all),\n",
    "    name=\"all values\",\n",
    "    mode=\"lines + markers\",\n",
    ")\n",
    "repeat_traces = [\n",
    "    go.Scatter(\n",
    "        y=100 * np.cumsum(var) / np.sum(var),\n",
    "        name=f\"repeat {i} values\",\n",
    "        mode=\"lines + markers\",\n",
    "    )\n",
    "    for i, var in enumerate(explained_variance_repeats)\n",
    "]\n",
    "averaged_trace = go.Scatter(\n",
    "    y=100 * np.cumsum(explained_variance_avg) / np.sum(explained_variance_avg),\n",
    "    name=\"averaged values\",\n",
    "    mode=\"lines + markers\",\n",
    ")\n",
    "ratio_plot.add_traces([all_trace, *repeat_traces, averaged_trace])\n",
    "ratio_plot.update_xaxes(title=dict(text=\"Component\"))\n",
    "ratio_plot.update_yaxes(title=dict(text=\"Cumulative Variance Explained (%)\"))\n",
    "# scree_plot.update_layout(height = 1000)\n",
    "ratio_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covariance heatmap\n",
    "covariance_plots = [go.Figure(), make_subplots(rows=1, cols=3), go.Figure()]\n",
    "all_trace = go.Heatmap(z=X_all.get_covariance(), zmin=-1, zmax=1)\n",
    "repeat_traces = [go.Heatmap(z=X.get_covariance(), zmin=-1, zmax=1) for X in X_repeat]\n",
    "averaged_trace = go.Heatmap(z=X_avg.get_covariance(), zmin=-1, zmax=1)\n",
    "titles = [\"All\", \"Per Sample\", \"Avg\"]\n",
    "covariance_plots[0].add_trace(all_trace)\n",
    "for i, trace in enumerate(repeat_traces):\n",
    "    covariance_plots[1].add_trace(trace, row=1, col=i + 1)\n",
    "covariance_plots[2].add_trace(averaged_trace)\n",
    "for i, (plot, title) in enumerate(zip(covariance_plots, titles)):\n",
    "    if i != 1:\n",
    "        height = 600\n",
    "        width = 600\n",
    "    else:\n",
    "        height = 600\n",
    "        width = 1800\n",
    "    plot.update_layout(height=height, width=width, title_text=title)\n",
    "    plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dataframe dimensionality\n",
    "reduced_components = pd.DataFrame(\n",
    "    X_all.components_.T, columns=[f\"PC{i+1}\" for i in range(X_all.n_components_)]\n",
    ")\n",
    "\n",
    "reduced_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings plot\n",
    "eigenvalues = X_all.explained_variance_.reshape(reduced_components.shape[1], 1)\n",
    "# load the reduced components with square rooted eigenvalues if we want to\n",
    "reduced_components *= np.sqrt(eigenvalues).T\n",
    "\n",
    "loading_plot = go.Figure()\n",
    "pc1_trace = go.Scatter(\n",
    "    x=wavenumber[0], y=reduced_components[\"PC1\"], mode=\"lines\", name=\"PC1\"\n",
    ")\n",
    "\n",
    "pc2_trace = go.Scatter(\n",
    "    x=wavenumber[0], y=reduced_components[\"PC2\"], mode=\"lines\", name=\"PC2\"\n",
    ")\n",
    "\n",
    "loading_plot.add_traces([pc1_trace, pc2_trace])\n",
    "loading_plot.update_xaxes(title=dict(text=\"Raman Shift\"))\n",
    "loading_plot.update_yaxes(title=dict(text=\"Loadings\"))\n",
    "loading_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA scatter\n",
    "scores = pd.DataFrame(\n",
    "    X_all.fit_transform(scaled_df),\n",
    "    index=labels,\n",
    "    columns=[f\"PC{i+1}\" for i in range(X_all.n_components_)],\n",
    ")\n",
    "markers = [\"circle\", \"square\", \"triangle-up\"]\n",
    "scatter_plot = go.Figure()\n",
    "\n",
    "for i, bacterium in enumerate(np.unique(bacteria)):\n",
    "    for j, rep in enumerate(np.unique(repeat)):\n",
    "        trace = go.Scatter(\n",
    "            x=scores[\"PC1\"].xs((bacterium, rep), level=(\"bacteria\", \"repeat\")),\n",
    "            y=scores[\"PC2\"].xs((bacterium, rep), level=(\"bacteria\", \"repeat\")),\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=colour[2 * i], symbol=markers[j]),\n",
    "            name=f\"{bacterium} - rep {rep}\",\n",
    "        )\n",
    "\n",
    "        scatter_plot.add_trace(trace)\n",
    "scatter_plot.update_xaxes(title=dict(text=\"PC1\"))\n",
    "scatter_plot.update_yaxes(title=dict(text=\"PC2\"))\n",
    "\n",
    "scatter_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA accuracy check\n",
    "y = bacteria\n",
    "X = X_all.fit_transform(scaled_df)\n",
    "print(X.shape)\n",
    "lda_scores = cross_val_score(LDA(), X, y, cv=4)\n",
    "print(\"Accuracy: %0.4f (+/- %0.4f)\" % (lda_scores.mean(), lda_scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_naive = LDA()\n",
    "X_lda_naive = lda_naive.fit_transform(scaled_df, bacteria)\n",
    "lda_naive_df = pd.DataFrame(\n",
    "    X_lda_naive,\n",
    "    index=labels,\n",
    "    columns=[f\"LD{i+1}\" for i in range(lda_naive.classes_.shape[0] - 1)],\n",
    ")\n",
    "lda_naive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_naive_plot = go.Figure()\n",
    "\n",
    "for i, bacterium in enumerate(np.unique(bacteria)):\n",
    "    trace = go.Scatter(\n",
    "        x=lda_naive_df[\"LD1\"].xs(bacterium, level=\"bacteria\"),\n",
    "        y=lda_naive_df[\"LD2\"].xs(bacterium, level=\"bacteria\"),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=colour[2 * i]),\n",
    "        name=f\"{bacterium}\",\n",
    "    )\n",
    "\n",
    "    lda_naive_plot.add_trace(trace)\n",
    "lda_naive_plot.update_xaxes(title=dict(text=\"LD1\"))\n",
    "lda_naive_plot.update_yaxes(title=dict(text=\"LD2\"))\n",
    "\n",
    "lda_naive_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay now let's do some LDA!\n",
    "lda = LDA()\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "lda_df = pd.DataFrame(\n",
    "    X_lda, index=labels, columns=[f\"LD{i+1}\" for i in range(lda.classes_.shape[0] - 1)]\n",
    ")\n",
    "lda_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_plot = go.Figure()\n",
    "\n",
    "for i, bacterium in enumerate(np.unique(bacteria)):\n",
    "    trace = go.Scatter(\n",
    "        x=lda_df[\"LD1\"].xs(bacterium, level=\"bacteria\"),\n",
    "        y=lda_df[\"LD2\"].xs(bacterium, level=\"bacteria\"),\n",
    "        mode=\"markers\",\n",
    "        marker=dict(color=colour[2 * i]),\n",
    "        name=f\"{bacterium}\",\n",
    "    )\n",
    "\n",
    "    lda_plot.add_trace(trace)\n",
    "lda_plot.update_xaxes(title=dict(text=\"LD1\"))\n",
    "lda_plot.update_yaxes(title=dict(text=\"LD2\"))\n",
    "\n",
    "lda_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively using LDA doesn't really alter things, *but*, in general, the PCA-LDA is more robust as the PCA matrix is orthogonal by construction, so we use the PCA-LDA approach for confusion matrix stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction quality of the model\n",
    "lda_test = LDA()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "lda_test.fit(X_train, y_train)\n",
    "score = lda_test.score(X_train, y_train)\n",
    "y_pred = lda_test.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "confusion_plot = px.imshow(\n",
    "    conf_mat, y=folders, x=folders, text_auto=True, aspect=\"auto\"\n",
    ")\n",
    "confusion_plot.update_xaxes(title_text=\"Predicted\")\n",
    "confusion_plot.update_yaxes(title_text=\"Actual\")\n",
    "\n",
    "confusion_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report\n",
    "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=folders))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = df.groupby(\"bacteria\").mean()\n",
    "std_df = df.groupby(\"bacteria\").std()\n",
    "intensity_data = df.to_numpy().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacing for evenly fitted spline is ~1.07 and scipy assumes delta = 1.0\n",
    "# doesn't affect derivative size too much (compared to threshold)\n",
    "# this cell plots X to check filter performance (0 - 299 for c-gluta, 300 - 599 for r-eryth and 600+ for m-bovis)\n",
    "X = intensity_data[:, 601]\n",
    "# These parameters are used later on so make sure this cell has run!!\n",
    "order = 2\n",
    "window = 5\n",
    "fig = go.Figure()\n",
    "intensity_trace = go.Scatter(\n",
    "    x=wavenumber[1],\n",
    "    y=X,\n",
    "    name=\"Raw\",\n",
    ")\n",
    "sg_trace = go.Scatter(\n",
    "    x=wavenumber[1],\n",
    "    y=savgol_filter(X, window, polyorder=order),\n",
    "    mode=\"lines\",\n",
    "    name=\"SG\",\n",
    ")\n",
    "sg_traced1 = go.Scatter(\n",
    "    x=wavenumber[1],\n",
    "    y=savgol_filter(X, window, polyorder=order, deriv=1),\n",
    "    mode=\"lines\",\n",
    "    name=\"SG 1st derivative\",\n",
    ")\n",
    "sg_traced2 = go.Scatter(\n",
    "    x=wavenumber[1],\n",
    "    y=savgol_filter(X, window, polyorder=order, deriv=2),\n",
    "    mode=\"lines\",\n",
    "    name=\"SG 2nd derivative\",\n",
    ")\n",
    "fig.add_traces([intensity_trace, sg_trace, sg_traced1, sg_traced2])\n",
    "\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply savgol filter on data and determine thresholds for bacteria\n",
    "sg_df = df.apply(\n",
    "    savgol_filter,\n",
    "    axis=1,\n",
    "    result_type=\"broadcast\",\n",
    "    window_length=window,\n",
    "    polyorder=order,\n",
    "    deriv=2,\n",
    ")\n",
    "thresholds = sg_df.groupby(\"bacteria\").max().to_numpy()\n",
    "thresholds = (7.5 / 100) * np.max(thresholds, axis=1)\n",
    "print(thresholds)\n",
    "barcode_freq = make_subplots(\n",
    "    rows=3,\n",
    "    cols=1,\n",
    "    subplot_titles=(\"c-glutamicum\", \"m-bovis\", \"r-erythropolis\"),\n",
    "    vertical_spacing=0.05,\n",
    ")\n",
    "for i, bacterium in enumerate(np.unique(bacteria)):\n",
    "    intensity_trace = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=avg_df.loc[bacterium],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"black\"),\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    upper = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=(avg_df.loc[bacterium] + std_df.loc[bacterium]),\n",
    "        mode=\"lines\",\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(68, 68, 68, 0.3)\",\n",
    "        opacity=0.3,\n",
    "        line=dict(color=\"rgba(255,255,255,0)\", width=0),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    lower = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=(avg_df.loc[bacterium] - std_df.loc[bacterium]),\n",
    "        mode=\"lines\",\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(68, 68, 68, 0.3)\",\n",
    "        opacity=0.3,\n",
    "        line=dict(color=\"rgba(255,255,255,0)\", width=0),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    barcode_freq.add_trace(intensity_trace, row=i + 1, col=1)\n",
    "    barcode_freq.add_trace(upper, row=i + 1, col=1)\n",
    "    barcode_freq.add_trace(lower, row=i + 1, col=1)\n",
    "    # generate histogram data - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2732026/\n",
    "    # count rows in each column that's above threshold\n",
    "    sg_df.loc[bacterium][sg_df.loc[bacterium] >= thresholds[i]] = 1\n",
    "    sg_df.loc[bacterium][sg_df.loc[bacterium] < thresholds[i]] = 0\n",
    "\n",
    "    counts = sg_df.loc[bacterium].sum() / sg_df.loc[bacterium].sum().max()\n",
    "    hist_trace = go.Bar(\n",
    "        x=wavenumber[1],\n",
    "        y=counts,\n",
    "        offset=0,\n",
    "        showlegend=False,\n",
    "        marker_color=colour[2 * i],\n",
    "        marker_line_width=0,\n",
    "    )\n",
    "    barcode_freq.add_trace(hist_trace, row=i + 1, col=1)\n",
    "barcode_freq.update_xaxes(title=dict(text=\"Raman Shift\"), row=3, col=1)\n",
    "barcode_freq.update_yaxes(title=dict(text=\"Intensity\"), row=2, col=1)\n",
    "barcode_freq.update_yaxes(range=[0, 1])\n",
    "barcode_freq.update_layout(bargap=0.0, height=1000)\n",
    "\n",
    "barcode_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply savgol filter on data and determine thresholds for bacteria\n",
    "sg_df = df.apply(\n",
    "    savgol_filter,\n",
    "    axis=1,\n",
    "    result_type=\"broadcast\",\n",
    "    window_length=window,\n",
    "    polyorder=order,\n",
    "    deriv=2,\n",
    ")\n",
    "thresholds = sg_df.groupby(\"bacteria\").max().to_numpy()\n",
    "thresholds = (5 / 100) * np.max(thresholds, axis=1)\n",
    "print(thresholds)\n",
    "barcode_col = make_subplots(\n",
    "    rows=3,\n",
    "    cols=1,\n",
    "    subplot_titles=(\"c-glutamicum\", \"m-bovis\", \"r-erythropolis\"),\n",
    "    vertical_spacing=0.05,\n",
    ")\n",
    "for i, bacterium in enumerate(np.unique(bacteria)):\n",
    "    intensity_trace = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=avg_df.loc[bacterium],\n",
    "        mode=\"lines\",\n",
    "        # line=dict(color=\"black\"),\n",
    "        line=dict(color=colour[2 * i]),\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    upper = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=(avg_df.loc[bacterium] + std_df.loc[bacterium]),\n",
    "        mode=\"lines\",\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(68, 68, 68, 0.3)\",\n",
    "        opacity=0.1,\n",
    "        # line=dict(color='rgba(255,255,255,0)', width=0),\n",
    "        line=dict(color=colour[2 * i], width=0),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    lower = go.Scatter(\n",
    "        x=wavenumber[1],\n",
    "        y=(avg_df.loc[bacterium] - std_df.loc[bacterium]),\n",
    "        mode=\"lines\",\n",
    "        fill=\"tonexty\",\n",
    "        fillcolor=\"rgba(68, 68, 68, 0.3)\",\n",
    "        opacity=0.3,\n",
    "        # line=dict(color='rgba(255,255,255,0)', width=0),\n",
    "        line=dict(color=colour[2 * i], width=0),\n",
    "        hoverinfo=\"skip\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "    # here we use the `counts` value to determine bar colour for wavenumber - https://aocs.onlinelibrary.wiley.com/doi/full/10.1007/s11746-016-2808-7?saml_referrer\n",
    "    # a key difference here is that they used the absolute second derivative value\n",
    "    # their choice of 1% is a bit mental since our data isn't as exciting, so i used 5%\n",
    "    sg_df.loc[bacterium][sg_df.loc[bacterium].abs() >= thresholds[i]] = 1\n",
    "    sg_df.loc[bacterium][sg_df.loc[bacterium].abs() < thresholds[i]] = 0\n",
    "\n",
    "    counts = sg_df.loc[bacterium].sum() / sg_df.loc[bacterium].sum().max()\n",
    "    hist_trace = go.Bar(\n",
    "        x=wavenumber[1],\n",
    "        y=[1] * len(wavenumber[1]),\n",
    "        offset=0,\n",
    "        showlegend=False,\n",
    "        marker_color=counts,\n",
    "        marker_line_width=0,\n",
    "        marker_colorscale=\"Greys\",\n",
    "    )\n",
    "    barcode_col.add_trace(intensity_trace, row=i + 1, col=1)\n",
    "    barcode_col.add_trace(upper, row=i + 1, col=1)\n",
    "    barcode_col.add_trace(lower, row=i + 1, col=1)\n",
    "    barcode_col.add_trace(hist_trace, row=i + 1, col=1)\n",
    "barcode_col.update_xaxes(title=dict(text=\"Raman Shift\"), row=3, col=1)\n",
    "barcode_col.update_yaxes(title=dict(text=\"Intensity\"), range=[0, 1], row=2, col=1)\n",
    "barcode_col.update_yaxes(range=[0, 1])\n",
    "barcode_col.update_layout(height=1000)\n",
    "barcode_col\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('michael-paper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "192c6aab3decc63fd6153f908548be74df1973b1cc7141fd1b7e4153cebb5287"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
